{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09591ad-11df-4dfe-9c20-0a3ad3925fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74570a91-b3e5-4a65-ae08-5e32635e64c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe4aa7f-459d-4e60-85f9-2d6702dd54d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 12:27:13.414996: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 12:27:14.212164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import SamProcessor\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daea3c77-00c8-4b43-b2b2-f2e5299e8f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeru/miniconda3/envs/llama-2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import SamModel\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248b1f2-a6dd-4bc0-98ce-71a8c102aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dea069-35f3-4ee5-978c-4ad5669dddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                              # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),       # Normalize pixel values to range [-1, 1]\n",
    "    transforms.RandomAffine(degrees=0, shear=0.2),      # Shear\n",
    "    transforms.RandomAffine(degrees=0, scale=(1-0.2, 1+0.2)),   # Zoom\n",
    "    transforms.RandomHorizontalFlip(p=0.5)             # Horizontal flip with probability 0.5\n",
    "])\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root='path/to/dataset', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e32cf-3c9e-4349-81a7-f51ae71c5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define DeepPhase Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3f8eee-c79b-4ca9-93c8-a7771fdda153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Update the CNN architecture for a 3-class classification\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        # Fully connected layer for 3 classes\n",
    "        self.fc = nn.Linear(17*17*32, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutions and max pooling layers\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=2)\n",
    "        # Flatten the tensor\n",
    "        x = x.view(-1, 17*17*32)\n",
    "        # Fully connected layer with no activation, activation will be included in the loss function (e.g., CrossEntropyLoss)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the updated model for 3-class classification\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b47e273-0835-4042-aa5e-30e41fef09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the custom loss function\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, beta):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Mean Squared Error\n",
    "        mse = torch.mean((targets - predictions) ** 2)\n",
    "        # Mean Absolute Error\n",
    "        mean_difference = torch.mean(torch.abs(targets - predictions))\n",
    "        # Custom loss as per the provided equation\n",
    "        loss = mse + self.beta * mean_difference\n",
    "        return loss\n",
    "\n",
    "# Example usage of the custom loss function\n",
    "# Assuming beta is provided\n",
    "beta_value = 0.5  # This can be any non-negative value, provided as hyperparameter\n",
    "custom_loss_function = CustomLoss(beta=beta_value)\n",
    "\n",
    "# Example tensors for predictions and targets\n",
    "predictions_example = torch.tensor([0.1, 0.2, 0.3], requires_grad=True)\n",
    "targets_example = torch.tensor([0.0, 0.25, 0.5])\n",
    "\n",
    "# Calculate loss\n",
    "loss = custom_loss_function(predictions_example, targets_example)\n",
    "loss.backward()  # Backpropagate to compute gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc647b-f7bf-4671-8632-5043758ab0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c40b08-0cf0-460e-bd3c-21380953e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "train_dataset = MyDataset()\n",
    "val_dataset = MyDataset()\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e889cf-2afa-4030-b666-cae013e93988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Assuming SimpleCNN, CustomLoss, and MyDataset are already defined\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_grid = {\n",
    "    'lr': [0.00001],\n",
    "    'batch_size': [10]\n",
    "}\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            # Get the inputs and labels\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Define the evaluation loop\n",
    "def evaluate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "# Prepare the datasets and dataloaders outside of the grid search loop to save time\n",
    "train_dataset = MyDataset()  # You need to implement this\n",
    "val_dataset = MyDataset()    # You need to implement this\n",
    "\n",
    "# Conduct the grid search\n",
    "best_params = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = SimpleCNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "    criterion = CustomLoss(beta=0.2).to(device)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Train the model for a fixed number of epochs\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = evaluate_model(model, val_loader, criterion)\n",
    "    \n",
    "    # Update the best parameters if the current model is better\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_params = params\n",
    "        # Optionally, save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Output the best parameters found\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Optionally, load the best model for further use or evaluation\n",
    "model_to_use = SimpleCNN()\n",
    "model_to_use.load_state_dict(torch.load('best_model.pth'))\n",
    "model_to_use.to(device)\n",
    "model_to_use.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-2",
   "language": "python",
   "name": "llama-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
